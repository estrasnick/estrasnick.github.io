<!DOCTYPE html>
<html>
  <head>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
      <title>Evan Strasnick — Towards Open-World Gesture Recognition</title>
      <meta name="viewport" content="width=device-width">
      <meta name="description" content="Evan Strasnick — HCI Researcher">

      <!-- syntax highlighting CSS -->
      <link rel="stylesheet" href=/academic/css/syntax.css>

      <!-- Custom CSS -->
      <link rel="stylesheet" href=/academic/css/main.css>

      <!-- Responsive CSS -->
      <link rel="stylesheet" href=/academic/css/responsive.css>

      <!-- Google Fonts -->
      <link rel="preconnect" href="https://fonts.googleapis.com">
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link href="https://fonts.googleapis.com/css2?family=DM+Serif+Display&family=Open+Sans:wght@300&family=Raleway:wght@300;600&display=swap" rel="stylesheet">



  </head>
  <body>
    <div class="site" id="top">
      <div class="sidebar" id="sidebar">
        <div class="header">

          <h1 class="title"><a href=/academic/><img id="headshot" src=/academic/images/3_web_cropped.jpg></a></h1>
          <h1 class="title" id="sidebar-name"><a href=/academic/>Evan<br>Strasnick</a></h1>
        </div>

        <div class="nav" id="div-nav">

          <div class="about" id="about-nav">
            <ul id="navlinks" class="nomarker">
                <li><a href=/academic/#top id="about-link" class="navlink">About</a></li>
                <li><a href=/academic/#publications id="research-link" class="navlink">Publications</a></li>
                <li><a href=/academic/#otherprojects id="proj-link" class="navlink">Other Projects</a></li>
            </ul>
          </div>
        </div>


        <div class="footer" id="about-footer">
          <div class="about" id="about-text">
            <p>PhD: Human-Computer Interaction</p>
            <p>He/him</p>
          </div>
          <div class="about" id="about-links">
            <p><a href=/academic/CV.pdf>Curriculum Vitae</a></p>
            <p><a href="https://scholar.google.com/citations?user=IpYVaVMAAAAJ&hl=en&oi=ao">Scholar</a></p>
            <p><a href="mailto:estrasnick@gmail.com">Email</a></p>
          </div>
        </div>

      </div>

      <div class="floatbutton">
        <div id="sidebar-button">
          <img id="hamburger" src=/academic/images/sidebar-button.png>
        </div>
      </div>

      <div class="content" id="home">

        <div id="post-info">
  <div id="cover-photo-container">
    
      <img id="cover-photo" src="/academic/images/owgr_q.png">
    
  </div>

  <div id="info-container">
    <h1 id="title">Towards Open-World Gesture Recognition</h1>
    <p>Junxiao Shen, Matthias De Lange, Xuhai Xu, Ran Tan, Enmin Zhou, Naveen Suda, Maciej Lazarewicz, Per Ola Kristensson, Amy Karlson, Evan Strasnick</p>
    <p>ISMAR, 2024.</p>
    <p>   </p>
    
  </div>
</div>

<div class="post textblock">
  Providing users with accurate gestural interfaces, such as gesture recognition based on wrist-worn devices, is a key challenge in mixed reality. However, static machine learning processes in gesture recognition assume that training and test data come from the same underlying distribution. Unfortunately, in real-world applications involving gesture recognition, such as gesture recognition based on wrist-worn devices, the data distribution may change over time. We formulate this problem of adapting recognition models to new tasks, where new data patterns emerge, as open-world gesture recognition (OWGR). We propose the use of continual learning to enable machine learning models to be adaptive to new tasks without degrading performance on previously learned tasks. However, the process of exploring parameters for questions around when, and how, to train and deploy recognition models requires resource-intensive user studies may be impractical. To address this challenge, we propose a design engineering approach that enables offline analysis on a collected large-scale dataset by systematically examining various parameters and comparing different continual learning methods. Finally, we provide design guidelines to enhance the development of an open-world wrist-worn gesture recognition process.
  

</div>



      </div>

    </div>
    <script src=/academic/scripts/responsive.js type="text/javascript"></script>
  </body>
</html>
